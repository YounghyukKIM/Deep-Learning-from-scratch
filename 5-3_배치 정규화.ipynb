{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9648b5",
   "metadata": {},
   "source": [
    "1. 배치 정규화란?\n",
    "    - 층마다 활성화값이 적절히 퍼지도록 강제하는 테크닉.\n",
    "    - 배치 정규화의 장점\n",
    "        - 학습 가속화\t\n",
    "        - 초깃값 의존 감소\t\n",
    "        - 오버피팅 억제\t\n",
    "    - 적용 위치\n",
    "        - 신경망의 각 Affine → (BN) → ReLU 순서로 삽입\n",
    "        - (혹은 ReLU 이후에 BN을 삽입하는 실험도 진행 중)\n",
    "\n",
    "2. 배치 정규화 알고리즘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49304f63",
   "metadata": {},
   "source": [
    "- 2.1 수식 (미니배치 $B = {x1, ..., xm}$)\n",
    "    - 1. 평균 계산\n",
    "        - $\\mu_B = \\frac{1}{m} \\sum_{i=1}^{m} x_i$\n",
    "    - 2. 분산 계산\n",
    "        - $\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu_B)^2$\n",
    "    - 3. 정규화\n",
    "        - $\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$\n",
    "            - $ϵ$ : 0으로 나누는 것을 막기 위한 아주 작은 값 (ex.10 −7)\n",
    "    - 4. 스케일 & 쉬프트 변환\n",
    "        - y_i = \\gamma \\hat{x}_i + \\beta\n",
    "            - $γ$ : 스케일(scale) 매개변수 (초기값 1)\n",
    "            - $β$ : 쉬프트(shift) 매개변수 (초기값 0)\n",
    "                - $γ,β$는 학습을 통해 업데이트됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b56516",
   "metadata": {},
   "source": [
    "- 2.2 계산 그래프 요약\n",
    "    - 입력 → 평균, 분산 계산 → 정규화 → γ, β로 변환 → 출력\n",
    "        - 순전파: 입력을 정규화하고 γ, β를 곱하고 더한다\n",
    "        - 역전파: 복잡하지만 자동미분(Autograd)으로 해결 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dca844",
   "metadata": {},
   "source": [
    "| 항목 | 배치 정규화 미사용 | 배치 정규화 사용 |\n",
    "|:----|:-------------------|:----------------|\n",
    "| 학습 속도 | 느림 또는 학습 실패 가능 | 빠름 |\n",
    "| 초깃값 영향 | 매우 민감 | 덜 민감 |\n",
    "| 오버피팅 | 심할 수 있음 | 억제 효과 있음 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd24d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
