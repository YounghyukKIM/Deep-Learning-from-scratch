{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdc22c2",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f406c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b34e18",
   "metadata": {},
   "source": [
    "1. ReLU 계층\n",
    "    - ReLU(Rectified Linear Unit) 함수는 입력이 0보다 크면 그대로 출력하고, 0 이하면 0을 출력한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f9d78",
   "metadata": {},
   "source": [
    "- 1.1 수식\n",
    "    - $y = \\begin{cases}x & (x > 0) \\\\0 & (x \\leq 0)\\end{cases}$\n",
    "    - 역전파 시\n",
    "        - $\\frac{\\partial y}{\\partial x} = \\begin{cases}1 & (x > 0) \\\\0 & (x \\leq 0)\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76641f0",
   "metadata": {},
   "source": [
    "- 1.2 ReLU 클래스 구현\n",
    "    - 순전파: 0 이하인 값을 모두 0으로 만든다.\n",
    "    - 역전파: 0 이하였던 위치의 gradient를 0으로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e344327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f008afe",
   "metadata": {},
   "source": [
    "2. Sigmoid 계층\n",
    "    - Sigmoid 함수는 입력을 0~1 범위로 부드럽게 압축한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2d9e4",
   "metadata": {},
   "source": [
    "- 2.1 수식\n",
    "    - $y = \\frac{1}{1 + e^{-x}}$\n",
    "    - 역전파 시\n",
    "        - $\\frac{\\partial y}{\\partial x} = y(1 - y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5bac0",
   "metadata": {},
   "source": [
    "- 2.2 Sigmoid 클래스 구현\n",
    "    - 순전파: Sigmoid 변환 수행\n",
    "    - 역전파: Sigmoid 출력 값을 이용해 gradient 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14278f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d2ace",
   "metadata": {},
   "source": [
    "3. Affine 계층\n",
    "    - Affine 변환은 선형 변환(행렬곱) + 편향(bias) 덧셈을 의미한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0320d9",
   "metadata": {},
   "source": [
    "- 3.1 수식\n",
    "    - $Y=XW+B$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a607dc",
   "metadata": {},
   "source": [
    "- 3.2 Affine 클래스 구현\n",
    "    - 순전파 : 입력과 가중치의 행렬곱 + 편향 덧셈\n",
    "    - 역전파 : \n",
    "        - 입력 x에 대한 기울기\n",
    "        - 가중치 W에 대한 기울기\n",
    "        - 편향 b에 대한 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092c7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2c243",
   "metadata": {},
   "source": [
    "4. Softmax-with-Loss 계층\n",
    "    - Softmax 계층과 Cross Entropy Error 계층을 합친 것.\n",
    "        - Softmax로 확률 분포를 만들고,\n",
    "        - Cross Entropy로 Loss를 계산한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6efd06",
   "metadata": {},
   "source": [
    "- 4.1 Softmax 함수\n",
    "    - 입력을 안정적으로 정규화 (오버플로 방지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93eb9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e36257",
   "metadata": {},
   "source": [
    "- 4.2 Cross Entropy Error 함수\n",
    "    - y : 예측 확률\n",
    "    - t : 정답 레이블 (원-핫 인코딩)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6df501",
   "metadata": {},
   "source": [
    "- 4.3 SoftmaxWithLoss 클래스 구현\n",
    "    - 순전파: 소프트맥스 → 크로스 엔트로피 계산\n",
    "    - 역전파: softmax 출력과 정답의 차이를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39fb8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b804e7",
   "metadata": {},
   "source": [
    "5. 테스트 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4355dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007620616629495912\n",
      "[ 0.00030165 -0.00253058  0.00222893]\n",
      "5.0076057626568575\n",
      "[ 3.01653061e-04 -3.31104402e-01  3.30802749e-01]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    swl = SoftmaxWithLoss()\n",
    "\n",
    "    # 예시1: 거의 맞춘 경우\n",
    "    a = np.array([1, 8, 3])\n",
    "    t = np.array([0, 1, 0])\n",
    "\n",
    "    print(swl.forward(a, t))  # 0.0076\n",
    "    print(swl.backward())     # 작은 오차\n",
    "\n",
    "    # 예시2: 많이 틀린 경우\n",
    "    a = np.array([1, 3, 8])\n",
    "\n",
    "    print(swl.forward(a, t))  # 5.0076\n",
    "    print(swl.backward())     # 큰 오차\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83020f",
   "metadata": {},
   "source": [
    "| 계층 | 역할 | 순전파 | 역전파 |\n",
    "|:----|:----|:------|:------|\n",
    "| ReLU | 0 이하를 0으로 만든다 | 입력값 중 0 이하를 0으로 | 0 이하의 미분을 0으로 |\n",
    "| Sigmoid | 0~1로 부드럽게 압축 | sigmoid 함수 적용 | y(1-y) 곱하기 |\n",
    "| Affine | 선형 변환 | 행렬곱 + 편향 | 입력, 가중치, 편향에 대한 미분 계산 |\n",
    "| Softmax-with-Loss | 확률화 + 손실 계산 | softmax + cross-entropy | 출력과 정답 차이 계산 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881942f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
